{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3341b4-d963-4181-a28f-d860e5b7d65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Open the PDF file\n",
    "pdf_path = \"reference_guide.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Function to extract text and save images\n",
    "def extract_pdf_content(doc):\n",
    "    pages_data = []\n",
    "    \n",
    "    # Loop through each page of the document\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)  # Load the page\n",
    "        \n",
    "        # Extract text from the page\n",
    "        page_text = page.get_text(\"text\")\n",
    "        \n",
    "        # Optional: Split text into chunks based on headers or paragraphs\n",
    "        page_chunks = page_text.split(\"\\n\\n\")  # Split by paragraphs or use other logic\n",
    "        \n",
    "        # Store text chunks along with their page number\n",
    "        pages_data.append({\n",
    "            \"page_number\": page_num + 1,\n",
    "            \"text_chunks\": page_chunks\n",
    "        })\n",
    "    \n",
    "    return pages_data\n",
    "\n",
    "# Extract text data\n",
    "pages_data = extract_pdf_content(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd603f87-74dd-4700-95c9-6c3a1153af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "# Function to process a single page\n",
    "def convert_single_page(page_number):\n",
    "    return convert_from_path(\"reference_guide.pdf\", first_page=page_number, last_page=page_number, dpi=150)\n",
    "\n",
    "# Create a folder to store the images\n",
    "output_folder = 'reference_guide_images'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Split the pages into ranges (now accounting for 664 pages)\n",
    "total_pages = 52\n",
    "page_numbers = range(1, total_pages + 1)\n",
    "\n",
    "# Use concurrent processing to convert pages\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(convert_single_page, page) for page in page_numbers]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        images = future.result()\n",
    "        for i, image in enumerate(images):\n",
    "            page_number = page_numbers[futures.index(future)]\n",
    "            image.save(f\"{output_folder}/page_{page_number}.png\", \"PNG\")\n",
    "            print(f\"Saved: page_{page_number}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40041d84-402d-48f3-a389-60ab9d602c46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "page_data_images = {}\n",
    "\n",
    "# Assuming pages_data is a list where the index corresponds to the page number minus one\n",
    "for page_number in range(1, 53):  # Assuming you have 664 pages\n",
    "    # Load the image for the current page\n",
    "    page_image = Image.open(f\"reference_guide_images/page_{page_number}.png\")\n",
    "    \n",
    "    # Get the text for the current page from pages_data (index is page_number - 1)\n",
    "    page_text = pages_data[page_number - 1]  # Access the text using index\n",
    "    \n",
    "    # Store both text and image in a dictionary\n",
    "    page_data_images[page_number] = {\"text\": page_text, \"image\": page_image}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3444b0d9-41ba-4ebf-aaf3-f25679378976",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_data_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a30d8-7c5f-4348-80b9-c89d34678cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Sentence-BERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Create a list of texts (each page's text) for embedding\n",
    "texts = [data[\"text\"] for data in page_data_images.values()]\n",
    "\n",
    "# Create embeddings for the texts\n",
    "embeddings = model.encode(texts, convert_to_tensor=True)\n",
    "\n",
    "# Store embeddings for each page number\n",
    "page_embeddings = {page_number: embeddings[page_number - 1] for page_number in range(1, 53)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69805ac5-6a35-4707-8918-a41bb619000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [str(data[\"text\"]) if data[\"text\"] is not None else \"\" for data in page_data_images.values()]\n",
    "embeddings = model.encode(texts, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde26049-ae00-4457-ade8-ffcc6c72a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_embeddings = {page_number: embeddings[page_number - 1] for page_number in range(1, 53)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e799256-c2e4-49fb-86dc-929cadf63e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "# Create a FAISS index (using L2 distance)\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])  # embedding dimension\n",
    "\n",
    "# Add the embeddings to the FAISS index\n",
    "index.add(embeddings.cpu().numpy())\n",
    "\n",
    "# Function to search for the most relevant page based on a query\n",
    "def search_query(query, k=3):\n",
    "    # Generate the embedding for the query\n",
    "    query_embedding = model.encode([query], convert_to_tensor=True)\n",
    "    \n",
    "    # Search for the top k most similar pages\n",
    "    distances, indices = index.search(query_embedding.cpu().numpy(), k)\n",
    "    \n",
    "    # Return the top k pages (page numbers) and their distances\n",
    "    results = [(index + 1, distances[0][i]) for i, index in enumerate(indices[0])]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435832a2-005b-4872-8b28-83e932724c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example query\n",
    "query = \"how do I start the windshield wipers?\"\n",
    "\n",
    "# Retrieve the top 3 most relevant pages\n",
    "results = search_query(query)\n",
    "\n",
    "# Display the results\n",
    "for page_number, distance in results:\n",
    "    print(f\"Page {page_number} (Distance: {distance}):\")\n",
    "    print(page_data_images[page_number][\"text\"])  # Display text for that page\n",
    "    page_data_images[page_number][\"image\"].show()  # Display the image for that page"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
